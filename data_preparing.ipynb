{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ спроса на самокаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные о поездках на самокатах представляют ценную информацию для понимания паттернов спроса и предпочтений пользователей. В нашем исследовании мы анализируем информацию о поездках на самокатах, включая дату и время начала и окончания поездки, местоположение старта и финиша, а также пройденное расстояние. Целью анализа является выявление основных трендов, факторов влияющих на спрос и закономерностей в использовании самокатов в различных районах города."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка библиотек и глобальных переменны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import timedelta\n",
    "import seaborn as sns\n",
    "import Levenshtein\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates\n",
    "from scipy.stats import shapiro\n",
    "from datetime import datetime\n",
    "from scipy.stats import f_oneway\n",
    "DIR = '/content/drive/MyDrive/'\n",
    "DIR = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Пользовательские функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data(data_df):\n",
    "    print('\\033[1m' + 'Изучим исходные данные' + '\\033[0m')\n",
    "    print(data_df.info())\n",
    "    # print(data_df.shape)\n",
    "\n",
    "    missed_cells = data_df.isnull().sum().sum(\n",
    "    )/(data_df.shape[0]*(data_df.shape[1]-1))\n",
    "    missed_rows = sum(data_df.isnull().sum(axis=1) > 0)/data_df.shape[0]\n",
    "    print('\\033[1m' + '\\nПроверка пропусков' + '\\033[0m')\n",
    "    print('Количество пропусков: {:.0f}'.format(data_df.isnull().sum().sum()))\n",
    "    print('Доля пропусков: {:.1%}'.format(missed_cells) + '\\033[0m')\n",
    "    print('Доля строк содержащих пропуски: {:.1%}'.format(missed_rows))\n",
    "\n",
    "    # Проверим дубликаты\n",
    "    print('\\033[1m' + '\\nПроверка на дубликаты' + '\\033[0m')\n",
    "    print('Количество полных дубликатов: ', data_df.duplicated().sum())\n",
    "\n",
    "    # Посмотрим на сами данные\n",
    "    print('\\033[1m' + '\\nПервые пять строк датасета' + '\\033[0m')\n",
    "    display(data_df.head(10))  # tail(7)\n",
    "\n",
    "    print('\\033[1m' + '\\nОписание количественных данных:' + '\\033[0m')\n",
    "    display(data_df.describe().T)\n",
    "\n",
    "    print('\\033[1m' + '\\nОписание категориальных данных:' + '\\033[0m')\n",
    "    display(data_df.describe(include='object').T)\n",
    "\n",
    "    print('\\033[1m' + '\\nВывод уникальных значений по каждому категориаьному признаку:' + '\\033[0m')\n",
    "    df_object = data_df.select_dtypes(include='object').columns\n",
    "\n",
    "    for i in df_object:\n",
    "        print('\\033[1m' + '_' + str(i) + '\\033[0m')\n",
    "        display(data_df[i].value_counts())\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_strings(df_main):\n",
    "    implicit_duplicates = []\n",
    "    reference_string = None\n",
    "    threshold_distance = 3  # Пороговое значение для считывания строки как дубликата\n",
    "    for index, string in df_main.iterrows():\n",
    "        if reference_string is None:\n",
    "            reference_string = string\n",
    "            continue\n",
    "        distance = Levenshtein.distance(reference_string, string)\n",
    "        if distance < threshold_distance:\n",
    "            implicit_duplicates.append((reference_string, string))\n",
    "        else:\n",
    "            reference_string = string\n",
    "    return implicit_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_graph(df, cat_feat):\n",
    "    '''\n",
    "    Функция отрисовки круговых диаграмм для категориальных переменных.\n",
    "    На вход: исходная таблица и список категориальных переменных.\n",
    "    На выходе: графики\n",
    "    '''\n",
    "\n",
    "    cols = 2\n",
    "    rows = int(np.ceil(len(cat_feat) / cols))\n",
    "\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(25, 20))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    count = -1\n",
    "    for i in range(rows):\n",
    "        for x in range(cols):\n",
    "            count += 1\n",
    "            col = cat_feat[count]\n",
    "            df1 = pd.DataFrame(df.groupby([col])[col].count())\n",
    "            axs[i, x].pie(x=df1[col],\n",
    "                          labels=df1.index,\n",
    "                          autopct='%1.1f%%',)\n",
    "            axs[i, x].title.set_text(str(col))\n",
    "\n",
    "    plt.suptitle('Круговые диаграммы категориальных признаков',\n",
    "                 fontsize=20, y=1.03)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(data, col_column):\n",
    "    '''\n",
    "    Функция отрисовки гистограмм и ящика с усами для количесвтенных переменных.\n",
    "    На вход: исходная таблица и список количественных переменных.\n",
    "    На выходе: графики\n",
    "    '''\n",
    "    rows = len(col_column)\n",
    "    f, ax = plt.subplots(rows,2, figsize=(8, 15))\n",
    "    f.tight_layout()\n",
    "    f.set_figheight(30)\n",
    "    f.set_figwidth(14)\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    \n",
    "    for i, col in enumerate(col_column):         \n",
    "        sns.histplot(data[col], kde=True, bins=24, ax = ax[i, 0])                    \n",
    "        sns.boxplot(data[col], ax = ax[i, 1])\n",
    "\n",
    "        ax[i, 0].set_xlabel(col)\n",
    "        ax[i, 1].set_xlabel(col)\n",
    "        ax[i, 0].set_ylabel('Количество')\n",
    "    plt.suptitle(\"Гистограмма и ящик с усами для количесвтенных данных\", fontsize=22, y=1.01)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_sum_test(x, Ptest):\n",
    "    \"\"\"\n",
    "    Функция проверяет нормальность/ненормальность распределения\n",
    "    по сумме 3-х тестов: Шапиро, Андерсона-Дарлинга, Харке-Бера\n",
    "\n",
    "    На выходе:\n",
    "    1 - ненормальное распределение\n",
    "    0 - нормальное распредление\n",
    "\n",
    "    Принцип большинства заложен.\n",
    "    Внутри есть функция расчёта критерия Андерсона, исходя из уровня значимсоти\n",
    "    \"\"\"\n",
    "\n",
    "    def anderson_chois_sig(A, Ptest):\n",
    "        if Ptest == 0.05:\n",
    "            ander = A[2]\n",
    "        elif Ptest == 0.01:\n",
    "            ander = A[4]\n",
    "        return ander\n",
    "\n",
    "    def normalnost_anderson(x, Ptest):\n",
    "        A2, crit, sig = anderson(x, dist='norm')\n",
    "        ad_pass = (A2 < crit)\n",
    "        norm = anderson_chois_sig(ad_pass, Ptest)\n",
    "        if norm == False:\n",
    "            return 1\n",
    "        return 0\n",
    "   # print(x)\n",
    "    p_shapiro = shapiro(x)[1]\n",
    "    p_jarque = jarque_bera(x)[1]\n",
    "\n",
    "    if p_shapiro < Ptest:\n",
    "        p_shapiros = 1\n",
    "    else:\n",
    "        p_shapiros = 0\n",
    "\n",
    "    if p_jarque < Ptest:\n",
    "        p_jarques = 1\n",
    "    else:\n",
    "        p_jarques = 0\n",
    "\n",
    "    p_anderson = normalnost_anderson(x, Ptest)  # 1 - ненормальное, 0 - нормальное\n",
    "\n",
    "    p_sum = p_shapiros + p_anderson + p_jarques\n",
    "\n",
    "    if (p_sum > 1):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.read_csv(\"rides.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка отработанного кода\n",
    "df_main.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = pd.read_csv(\"weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка отработанного кода\n",
    "df_weather.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Осмотр данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Основаня таблица "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОПИСАТЕЛЬНЫЙ АНАЛИЗ\n",
    "check_data(df_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ГРАФИЧЕСКИЙ АНАЛИЗ количественных данных данных\n",
    "num_features = df_main.select_dtypes(exclude=[object]).columns\n",
    "\n",
    "# Проверка\n",
    "num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Вывод: Отсутвует время начала и время конца поездки*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(df_main, df_main.select_dtypes(exclude=[object]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ГРАФИЧЕСКИЙ АНАЛИЗ категориальных данных\n",
    "cat_features = df_main.select_dtypes(include=[object]).columns\n",
    "\n",
    "# Проверка\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Вывод: Есть лишние данные в виде даты старта и даты окончания*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Таблица с погодой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОПИСАТЕЛЬНЫЙ АНАЛИЗ\n",
    "check_data(df_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ГРАФИЧЕСКИЙ АНАЛИЗ количественных данных данных\n",
    "num_features = df_weather.select_dtypes(exclude=[object]).columns\n",
    "\n",
    "# Проверка\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ГРАФИЧЕСКИЙ АНАЛИЗ категориальных данных\n",
    "cat_features = df_weather.select_dtypes(include=[object]).columns\n",
    "\n",
    "# Проверка\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Вывод: Не правильно назначенны типы данных*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Основная таблица:** \n",
    "* Есть дубли.\n",
    "* Привести названия столбцов в соответствие с требованием питона.\n",
    "* Есть выбросы в distanse.\n",
    "* Есть пропуски.\n",
    "* Есть NaN.\n",
    "* Не правильно обозначенны типы данных.\n",
    "* Дописать выводы!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Основаня таблица "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приводим к PEP-8 Названия столбов\n",
    "df_main.columns = df_main.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ПРОВЕРКА ОТРАБОТКИ КОДА\n",
    "df_main.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Вывод: всё нормально*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняем Пропуски NaN\n",
    "df_main.fillna(np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приводим 'start_location' и 'end_location' к уникальным занчениям без повтроения.\n",
    "def to_normal(means):\n",
    "    means = means.lower()\n",
    "    means = means.replace(' ', '')\n",
    "    means = means.replace('ул', 'ул.')\n",
    "    means = means.replace('ул..', 'ул.')\n",
    "    means = means.replace('ул.', '')\n",
    "    \n",
    "    return means\n",
    "\n",
    "\n",
    "df_main['start_location'] = df_main['start_location'].apply(to_normal)\n",
    "df_main['end_location'] = df_main['end_location'].apply(to_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приводим 'start_district' и 'end_district' к уникальным занчениям без повтроения.\n",
    "replc = {\n",
    "    'Северо-Западный': 'северо-западный',\n",
    "    'северо западный': 'северо-западный',\n",
    "    'Северо Западный': 'северо-западныйй',\n",
    "    'Юго-Восточный': 'юго-восточный',\n",
    "    'Ленинский': 'ленинский',\n",
    "    'Октябрьский': 'октябрьский',\n",
    "    'Центральный': 'центральный',\n",
    "    'Заречный': 'заречный',\n",
    "    'Ленинский': 'ленинский',\n",
    "    'Октябрьский': 'октябрьский',\n",
    "\n",
    "}\n",
    "\n",
    "# Проходим по столбцу 'категория' и заменяем значения согласно словарю замен\n",
    "df_main['start_district'] = df_main['start_district'].replace(replc)\n",
    "df_main['end_district'] = df_main['end_district'].replace(replc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем что остались только уникальные занчения и потоврений больше нет.\n",
    "print('\\033[1m' + '\\nВывод уникальных значений по каждому категориаьному признаку:'+ '\\033[0m')    \n",
    "df_object = df_main.select_dtypes(include='object').columns\n",
    "for i in df_object:\n",
    "        print('\\033[1m' + '_'+ str(i) + '\\033[0m')\n",
    "        display(df_main[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 20)\n",
    "# Находим явыне дубликаты и удаляем их \n",
    "dulc = df_main.duplicated(keep=False)\n",
    "df_main.drop_duplicates(inplace=True)\n",
    "\n",
    "#Явыне дубликаты\n",
    "df_main[dulc].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Убираем выбросы\n",
    "# Использование межквартильного размаха для удаления выбросов из столбца 'Distance'\n",
    "Q1 = df_main['distance'].quantile(0.25)\n",
    "Q3 = df_main['distance'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Удаление выбросов\n",
    "df_main = df_main[(df_main['distance'] > lower_bound) & (df_main['distance'] < upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняем пропуски в distance\n",
    "# Преобразуем столбцы с датами в формат datetime\n",
    "df_main['start_date'] = pd.to_datetime(df_main['start_date'])\n",
    "df_main['end_date'] = pd.to_datetime(df_main['end_date'])\n",
    "\n",
    "# Вычисляем время, затраченное на поездку, в минутах\n",
    "df_main['travel_time'] = (df_main['end_date'] -\n",
    "                          df_main['start_date']).dt.total_seconds() / 60 / 60\n",
    "\n",
    "# Вычисляем среднюю скорость\n",
    "average_speed = df_main['distance'].median() / df_main['travel_time'].median()\n",
    "\n",
    "# Заполняем пропуски в столбце distance средним значением скорости\n",
    "df_main['distance'].fillna(df_main['travel_time'] *\n",
    "                           average_speed, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняем пропущенное end_date\n",
    "\n",
    "# Вычисляем медиану времени поездки и медиану расстояния\n",
    "median_travel_time = df_main['travel_time'].median()\n",
    "median_distance = df_main['distance'].median()\n",
    "\n",
    "# Заполняем пропуски в столбце Travel Time медианным значением времени поездки\n",
    "df_main['travel_time'].fillna(median_travel_time, inplace=True)\n",
    "\n",
    "# Вычисляем медиану скорости\n",
    "median_speed_m_per_min = median_distance / median_travel_time\n",
    "\n",
    "# Заполняем пропуски в столбце end_date с использованием медианной скорости\n",
    "df_main['end_date'].fillna(df_main['start_date'] + pd.to_timedelta(\n",
    "    df_main['distance'] / median_speed_m_per_min, unit='min'), inplace=True)\n",
    "\n",
    "# Округляем значения до ближайшего целого числа end_date\n",
    "df_main['end_date'] = df_main['end_date'].dt.floor('min')\n",
    "\n",
    "# Округляем значения до ближайшего целого числа start_date\n",
    "df_main['start_date'] = df_main['start_date'].dt.floor('min')\n",
    "\n",
    "# Удаляем временный столбец с временем поездки\n",
    "df_main.drop('travel_time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data(df_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Таблица с погодой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приводим к PEP-8 Названия столбов\n",
    "df_weather.columns = df_weather.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняем Пропуски NaN\n",
    "df_weather.fillna(np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather[df_weather.isna().any(axis=1)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование столбца Datetime в формат datetime\n",
    "df_weather[\"datetime\"] = pd.to_datetime(df_weather[\"datetime\"])\n",
    "\n",
    "# Установка индекса DataFrame по столбцу Datetime\n",
    "df_weather.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "# Интерполяция только для пропущенных значений в столбце Temperature\n",
    "df_weather[\"temperature\"] = df_weather[\"temperature\"].interpolate(method=\"linear\", limit_direction=\"both\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_graph(df_main, df_main.select_dtypes(include=[object]).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Проверка работы с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Основаня таблица "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ещё раз применим функцию первичноо осмотра данных\n",
    "check_data(df_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_graph(df_main, df_main.select_dtypes(include=[object]).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы по работе с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Таблица с погодой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ещё раз применим функцию первичноо осмотра данных\n",
    "check_data(df_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Проведение расчётов и иследований"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Рассчёт итоговой стоимости поездки с учетом применения промокода на бесплатный старт."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_of_day_on_week(date):\n",
    "    import datetime\n",
    "    zero_date = datetime.datetime(2023, 4, 22)\n",
    "    delta_date = date - zero_date\n",
    "    delta_days = delta_date.days + 5\n",
    "    num_of_day = delta_days % 7\n",
    "    # print(date, num_of_day)\n",
    "    return num_of_day\n",
    "\n",
    "\n",
    "def get_cost_of_minute(date):\n",
    "    num_of_day = get_num_of_day_on_week(date)\n",
    "    price = 0\n",
    "    if 0 <= num_of_day <= 4:\n",
    "        if 1 <= date.hour < 6:\n",
    "            price = 3\n",
    "        elif 6 <= date.hour < 10:\n",
    "            price = 4\n",
    "        elif 10 <= date.hour < 16:\n",
    "            price = 5\n",
    "        elif 16 <= date.hour < 22:\n",
    "            price = 6\n",
    "        elif 22 <= date.hour or date.hour < 1:\n",
    "            price = 5\n",
    "    else:\n",
    "        if 1 <= date.hour < 6:\n",
    "            price = 3\n",
    "        elif 6 <= date.hour < 10:\n",
    "            price = 4\n",
    "        elif 10 <= date.hour < 16:\n",
    "            price = 6\n",
    "        elif 16 <= date.hour < 22:\n",
    "            price = 7\n",
    "        elif 22 <= date.hour or date.hour < 1:\n",
    "            price = 6\n",
    "    return price\n",
    "\n",
    "\n",
    "def get_price(start_time, end_time, promo_used):\n",
    "    price = get_cost_of_minute(start_time)\n",
    "    minutes = (end_time - start_time).seconds // 60\n",
    "    return (promo_used + 1) % 2 * 30 + minutes * price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main['cost'] = df_main.apply(lambda row: get_price(row['start_date'], row['end_date'], row['promo']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Смотрим на результат.\n",
    "df_main.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Проверяем, стимулирует ли акция с бесплатным стартом по понедельникам спрос насамокаты. Окупается ли она."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand scooter - спрос на самокаты (почасовой)\n",
    "dem_scoot = df_main[['start_date', 'promo', 'cost']]\n",
    "dem_scoot['frequency'] = 1\n",
    "dem_scoot = dem_scoot.resample('1h', on='start_date').agg({'promo':'sum', 'cost': 'sum', 'frequency': 'count'})\n",
    "dem_scoot.reset_index(inplace=True)\n",
    "dem_scoot.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# По понедельникам с 6:00 до 10:00 акция «Бесплатный старт» по промокоду.\n",
    "dem_scoot_promo_time = dem_scoot[(6 <= dem_scoot['start_date'].dt.hour) \n",
    "                                 & (dem_scoot['start_date'].dt.hour <= 9)]\n",
    "dem_scoot_promo_time = dem_scoot_promo_time.resample('1d', on='start_date').agg({'promo':'sum', 'cost': 'sum', 'frequency': 'sum'})\n",
    "dem_scoot_promo_time.reset_index(inplace=True)\n",
    "# В dem_scoot_promo_time хранится информация о спросе по дням во временное окно акции\n",
    "dem_scoot_promo_time.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthes_translate = {4: 'апреле',\n",
    "                     5: 'мае',\n",
    "                     6: 'июне',\n",
    "                     7: 'июле'}\n",
    "monthes = dem_scoot_promo_time['start_date'].dt.month.unique()\n",
    "\n",
    "fig, axs = plt.subplots(nrows=len(monthes), figsize=(16, 16))\n",
    "fig.suptitle('Время с 6:00 по 10:00', fontweight='bold', fontsize=14)\n",
    "\n",
    "for i, m in enumerate(monthes):\n",
    "    dem_scoot_data = dem_scoot_promo_time[(dem_scoot_promo_time['start_date'].dt.month == m)]\n",
    "\n",
    "    x_values = dem_scoot_data['start_date']\n",
    "    y_values = dem_scoot_data['frequency']\n",
    "\n",
    "    dates = matplotlib.dates.date2num(x_values)\n",
    "\n",
    "    axs[i].plot_date(dates, y_values, color='#DBE2E9', linestyle='-')\n",
    "\n",
    "    promo_rides = dem_scoot_data[dem_scoot_data['promo'] > 0]\n",
    "\n",
    "    x_values = promo_rides['start_date']\n",
    "    y_values = promo_rides['frequency']\n",
    "\n",
    "    dates = matplotlib.dates.date2num(x_values)\n",
    "    axs[i].plot_date(dates, y_values, label='с промокодом')\n",
    "    \n",
    "\n",
    "    no_promo_rides = dem_scoot_data[dem_scoot_data['promo'] == 0]\n",
    "\n",
    "    x_values = no_promo_rides['start_date']\n",
    "    y_values = no_promo_rides['frequency']\n",
    "\n",
    "    dates = matplotlib.dates.date2num(x_values)\n",
    "    axs[i].plot_date(dates, y_values, label='без промокода')\n",
    "\n",
    "    axs[i].tick_params(axis='x', labelrotation=90)\n",
    "    axs[i].legend(loc=\"upper left\")\n",
    "    axs[i].set_xlabel('Время')\n",
    "    axs[i].set_ylabel('Спрос')\n",
    "    axs[i].set_title(f'Спрос в {monthes_translate[m]}', fontweight='bold')\n",
    "    axs[i].grid(color='#F1EDF2')\n",
    "    axs[i].xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод акция с промокодом**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Исследование корреляции между параметрами погодных условий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Таблица с почасовым спросом на самокаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand scooter - спрос на самокаты (почасовой)\n",
    "dem_scoot.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Определяем необходимое количесво самокатов в каждой точке и в каждом районе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations это list всевозможных локаций(точек)\n",
    "locations = set(df_main['start_location'].unique())\n",
    "locations = locations.union(set(df_main['start_location'].unique()))\n",
    "locations = list(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Будем считать что каждый день в 6:00 на точках появляется необходимое количество самокатов,\n",
    "иначе будет накапливаться минус в точках где откуда самокаты чаще уезжают(/ШУТКА: Завода производящего самокаты там нет/)\n",
    "\n",
    "Время 6:00 выбрано потому что предполагаем что в этот час начинается движение, запускается цикл спроса \n",
    "(работники, студенты, ... направляются в свои учреждения)\n",
    "'''\n",
    "locations_traffic = dict()\n",
    "\n",
    "for location in locations:\n",
    "    df_start = df_main[df_main['start_location'] == location][['start_date', 'cost']]\n",
    "    df_start['traffic'] = 1\n",
    "    df_start.columns = ['date', 'cost', 'traffic']\n",
    "\n",
    "    df_end = df_main[df_main['end_location'] == location][['end_date', 'cost']]\n",
    "    df_end['traffic'] = -1\n",
    "    df_end.columns = ['date', 'cost', 'traffic']\n",
    "    df_location = pd.concat([df_start, df_end], ignore_index=True)\n",
    "    df_location = df_location.sort_values(by='date')\n",
    "    # df_location = df_location.resample('1h', on='date').agg({'traffic': 'sum'}).reset_index()\n",
    "    df_location['traffic_cum'] = df_location.resample('d', on='date')['traffic'].cumsum()\n",
    "    df_location['traffic_cum_cont'] = df_location['traffic'].cumsum()\n",
    "    locations_traffic[location] = df_location\n",
    "df_location.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Предполагаю что количество необходимых самокатов в точках зависит от дня недели.\n",
    "Поэтому считаю минимум по траффику самокатов в каждой точке по каждому дню отдельно,\n",
    "также считаю минимум за все время и среднее за все время по минимумам по дням недели в точке.\n",
    "\n",
    "Минимальное будет браться среди отрицательных чисел, \n",
    "так как нам важно понять сколько самокатов необходимо для того чтобы каждый смог воспользоваться услугой.\n",
    "Человек не может воспользоваться услугой когда число самокатов в точке отрицательно(нет самокатов).\n",
    "'''\n",
    "df_locations_minuse_traffic_stat = pd.DataFrame({'location': [], \n",
    "                                 'mean_min_at_1d': [], \n",
    "                                 'min_at_all_time_1d': [],\n",
    "                                 'mean_min_at_2d': [], \n",
    "                                 'min_at_all_time_2d': [],\n",
    "                                 'mean_min_at_3d': [], \n",
    "                                 'min_at_all_time_3d': [],\n",
    "                                 'mean_min_at_4d': [], \n",
    "                                 'min_at_all_time_4d': [],\n",
    "                                 'mean_min_at_5d': [], \n",
    "                                 'min_at_all_time_5d': [],\n",
    "                                 'mean_min_at_6d': [], \n",
    "                                 'min_at_all_time_6d': [],\n",
    "                                 'mean_min_at_7d': [], \n",
    "                                 'min_at_all_time_7d': [],\n",
    "                                 'mean_min_at_all_time': [],\n",
    "                                 'min_at_all_time': []})\n",
    "\n",
    "'''\n",
    "Посмотрим на количество самокатов которое остается в конце дня\n",
    "'''\n",
    "df_locations_remains_stat = pd.DataFrame({'location': [], \n",
    "                                 'mean_at_1d': [], \n",
    "                                 'max_at_all_time_1d': [],\n",
    "                                 'mean_at_2d': [], \n",
    "                                 'max_at_all_time_2d': [],\n",
    "                                 'mean_at_3d': [], \n",
    "                                 'max_at_all_time_3d': [],\n",
    "                                 'mean_at_4d': [], \n",
    "                                 'max_at_all_time_4d': [],\n",
    "                                 'mean_at_5d': [], \n",
    "                                 'max_at_all_time_5d': [],\n",
    "                                 'mean_at_6d': [], \n",
    "                                 'max_at_all_time_6d': [],\n",
    "                                 'mean_at_7d': [], \n",
    "                                 'max_at_all_time_7d': [],\n",
    "                                 'mean_at_all_time': [],\n",
    "                                 'max_at_all_time': []})\n",
    "\n",
    "for location in locations_traffic:\n",
    "    location_traffic_day = locations_traffic[location].resample('1d', origin='2023-04-01 06:00:00', on='date').agg({'traffic': 'sum', 'traffic_cum': 'min'})\n",
    "    location_traffic_day.reset_index(inplace=True)\n",
    "    location_traffic_day['num_day'] = location_traffic_day['date'].apply(get_num_of_day_on_week)\n",
    "\n",
    "    # Для df_locations_minuse_traffic_stat\n",
    "    location_stat = [location]\n",
    "    for day in location_traffic_day['num_day'].unique():\n",
    "        min_traffics_at_day = location_traffic_day[(location_traffic_day['num_day'] == day)\n",
    "                                                    & (location_traffic_day['traffic_cum'] < 0)]['traffic_cum']\n",
    "        mean_min_at_day = min_traffics_at_day.mean()\n",
    "        min_at_all_time = min_traffics_at_day.min()\n",
    "        location_stat.extend([mean_min_at_day, min_at_all_time])\n",
    "    location_stat.append(location_traffic_day[location_traffic_day['traffic_cum'] < 0]['traffic_cum'].mean())\n",
    "    location_stat.append(location_traffic_day[location_traffic_day['traffic_cum'] < 0]['traffic_cum'].min())\n",
    "    df_locations_minuse_traffic_stat.loc[len(df_locations_minuse_traffic_stat)] = location_stat\n",
    "\n",
    "    # Для df_locations_remains_stat\n",
    "    location_stat = [location]\n",
    "    for day in location_traffic_day['num_day'].unique():\n",
    "        min_traffics_at_day = location_traffic_day[location_traffic_day['num_day'] == day]['traffic']\n",
    "        mean_min_at_day = min_traffics_at_day.mean()\n",
    "        min_at_all_time = min_traffics_at_day.max()\n",
    "        location_stat.extend([mean_min_at_day, min_at_all_time])\n",
    "    location_stat.append(location_traffic_day['traffic'].mean())\n",
    "    location_stat.append(location_traffic_day['traffic'].max())\n",
    "    df_locations_remains_stat.loc[len(df_locations_remains_stat)] = location_stat\n",
    "\n",
    "\n",
    "df_locations_minuse_traffic_stat = df_locations_minuse_traffic_stat.fillna(0)\n",
    "cols = df_locations_minuse_traffic_stat.columns.to_list()\n",
    "cols.pop(0)\n",
    "for col in cols:\n",
    "    df_locations_minuse_traffic_stat[col] = df_locations_minuse_traffic_stat[col].astype(int)\n",
    "df_locations_minuse_traffic_stat.sort_values(by='min_at_all_time', inplace=True)\n",
    "\n",
    "df_locations_remains_stat = df_locations_remains_stat.fillna(0)\n",
    "cols = df_locations_remains_stat.columns.to_list()\n",
    "cols.pop(0)\n",
    "for col in cols:\n",
    "    df_locations_remains_stat[col] = df_locations_remains_stat[col].astype(int)\n",
    "df_locations_remains_stat.sort_values(by='mean_at_all_time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locations_minuse_traffic_stat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_locations_remains_stat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "В датафрейме информация о том сколько самокатов должно быть в точке утром в 6:00 для того чтобы полностью удовлетворить спрос\n",
    "'''\n",
    "df_necessary_quantity_scoots = df_locations_minuse_traffic_stat[['location', 'min_at_all_time']]\n",
    "df_necessary_quantity_scoots.loc[:, 'min_at_all_time'] = df_necessary_quantity_scoots['min_at_all_time'].abs()\n",
    "df_necessary_quantity_scoots.columns = ['location', 'necessary_quantity']\n",
    "df_necessary_quantity_scoots = df_necessary_quantity_scoots.reset_index().drop('index', axis=1)\n",
    "df_necessary_quantity_scoots.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Попытка анализировать трафик в точках по наличию тренда,\n",
    "строю регресию и сортирую точки по углу полученой линии \n",
    "\n",
    "'''\n",
    "def is_trand(data):\n",
    "    x = np.arange(0, len(data))\n",
    "    y = np.array(data)\n",
    "\n",
    "    z = np.polyfit(x, y, 1)\n",
    "    return z[0], z[1]\n",
    "\n",
    "\n",
    "df_loc_traf_cum_cont = pd.DataFrame({'location': [], 'traffic_cum_cont': [], 'mean_traffic_cum_cont': [], 'reg_tg': [], 'reg_b': []})\n",
    "for location in locations:\n",
    "    df_location_traffic = locations_traffic[location]\n",
    "\n",
    "    res = is_trand(df_location_traffic['traffic_cum_cont'])\n",
    "    df_loc_traf_cum_cont.loc[len(df_loc_traf_cum_cont)] = [location, \n",
    "                                                           df_location_traffic.loc[len(df_location_traffic) - 1, 'traffic_cum_cont'],\n",
    "                                                           df_location_traffic['traffic_cum_cont'].mean(),\n",
    "                                                           res[0],\n",
    "                                                           res[1]]\n",
    "x_ = 100\n",
    "df_loc_traf_cum_cont['reg_dec'] = df_loc_traf_cum_cont['reg_tg'] * x_**2 + df_loc_traf_cum_cont['reg_b'] + x_\n",
    "df_loc_traf_cum_cont.sort_values(by='reg_dec', inplace=True)\n",
    "df_loc_traf_cum_cont.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_num_day = {\n",
    "    0: 'пн',\n",
    "    1: 'вт',\n",
    "    2: 'ср',\n",
    "    3: 'чт',\n",
    "    4: 'пт',\n",
    "    5: 'сб',\n",
    "    6: 'вс'\n",
    "}\n",
    "\n",
    "\n",
    "month = 7\n",
    "fig, axs = plt.subplots(nrows=3, figsize=(16, 16))\n",
    "fig.suptitle(f'Трафик в {monthes_translate[month]} (trafic_1)', fontweight='bold', fontsize=14)\n",
    "\n",
    "for i, location in enumerate(['спортивная', 'советская', 'зеленая']):\n",
    "    df_location = locations_traffic[location]\n",
    "\n",
    "    x = df_location[df_location['date'].dt.month == month]['date']\n",
    "    y_returns = df_location[df_location['date'].dt.month == month]['traffic_cum']\n",
    "\n",
    "\n",
    "    axs[i].fill_between(x, y_returns, 0, where=y_returns >= 0, facecolor='green', interpolate=True, alpha=0.7)\n",
    "    axs[i].fill_between(x, y_returns, 0, where=y_returns <= 0, facecolor='red', interpolate=True, alpha=0.7)\n",
    "\n",
    "    days = x.reset_index().set_index('date').resample('d').sum().reset_index().drop('index', axis=1)['date']\n",
    "    xtickvals = [str(date.date().day) + \"-\" + name_num_day[get_num_of_day_on_week(date)] for date in days]\n",
    "    \n",
    "\n",
    "    axs[i].grid(alpha=0.2)\n",
    "    axs[i].xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
    "    axs[i].set_xticks(days)\n",
    "    axs[i].set_xlim(days.iloc[0], days.iloc[len(days) - 1] + timedelta(days=1))\n",
    "    axs[i].set_ylim(-20, 20)\n",
    "\n",
    "    axs[i].set_xticklabels(xtickvals, rotation=90)\n",
    "    \n",
    "    axs[i].set_xlabel('Время')\n",
    "    axs[i].set_ylabel('Трафик')\n",
    "    axs[i].set_title(f'Улица {location.capitalize()}')\n",
    "\n",
    "fig.tight_layout()\n",
    "''' \n",
    "Ниже график trafic_1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_num_day = {\n",
    "    0: 'пн',\n",
    "    1: 'вт',\n",
    "    2: 'ср',\n",
    "    3: 'чт',\n",
    "    4: 'пт',\n",
    "    5: 'сб',\n",
    "    6: 'вс'\n",
    "}\n",
    "\n",
    "# streets = ['спортивная', 'советская', 'зеленая']\n",
    "streets = df_loc_traf_cum_cont['location'].to_list()[:5] + ['советская'] + df_loc_traf_cum_cont['location'].to_list()[-5:]\n",
    "fig, axs = plt.subplots(nrows=len(streets), figsize=(16, 6 * len(streets)))\n",
    "fig.suptitle('Трафик (trafic_2)', fontweight='bold', fontsize=14)\n",
    "\n",
    "for i, location in enumerate(streets):\n",
    "    df_location = locations_traffic[location]\n",
    "\n",
    "    x = df_location['date']\n",
    "    y_returns = df_location['traffic'].cumsum()\n",
    "\n",
    "\n",
    "    axs[i].fill_between(x, y_returns, 0, where=y_returns >= 0, facecolor='green', alpha=0.7)\n",
    "    axs[i].fill_between(x, y_returns, 0, where=y_returns <= 0, facecolor='red', alpha=0.7)\n",
    "\n",
    "    \n",
    "\n",
    "    axs[i].grid(alpha=0.2)\n",
    "    axs[i].xaxis.set_major_locator(mdates.DayLocator(interval=5))\n",
    "\n",
    "    \n",
    "    axs[i].set_xlabel('Время')\n",
    "    axs[i].set_ylabel('Трафик')\n",
    "    axs[i].set_title(f'Улица {location.capitalize()}')\n",
    "    axs[i].tick_params(axis='x', labelrotation=90)\n",
    "\n",
    "fig.tight_layout()\n",
    "''' \n",
    "Ниже график trafic_2\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Для графиков были взяты топ-5 улиц сверху и снизу остсортированного датафрейма df_loc_traf_cum_cont\n",
    "Датафрейм df_loc_traf_cum_cont был отсортирован по возрастанию площади под линией регрессии построенной по трафику.\n",
    "Сделано это было для того чтобы определить точки с возраст./убыв. трендом количества самокатов. \n",
    "Далее были выведены графики для проверки соответствия\n",
    "Улица 'советская' добавлена в качестве премера той улицы, которую не стоит использовать для балансировки.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "\n",
    "Из датафрэйма df_locations_remains_stat отсортированного по возрастанию среднего по оставшимся самокатам в 6:00\n",
    "Видно что самокаты в целом в конце дня если и остаются то в малом количестве, что делает не выгодным их транспортировку в другие точки,\n",
    "а также из датафрэйма df_necessary_quantity_scoots видно что во все точки необходимо поставлять самокаты чтобы покрыть спрос\n",
    "Получается что перераспредилить самокаты в конце дня не получится.\n",
    "Возможно для перераспределения самокатов нужно выбирать разное время для каждой точки, тогда удасться покрыть спрос, так как в некоторые точки самокаты чаще приехжают,\n",
    "а из других уезжают (например: 'спортивная', 'зеленая') -> Это видно из графика trafic_2 на улицу 'зеленая' чаще приезжают, поэтому если самокаты от туда не увозить,\n",
    "то они будут копиться, к примеру их можно увозить на улицу 'спортивная'.\n",
    "\n",
    "Но сказать что стабильно можно перенаправлять самокаты в конце дня с какой то улицы не получается, потому что есть много минимумов, которые видно из графика,\n",
    "и предугадать когда можно увезти получится только при более детальном исследованиии и при отслеживании самокатов online\n",
    "\n",
    "Пока что кажется что по этим данным решить задачу балансировки самокатов offline не получится.\n",
    "Но можно сказать примерно из каких точек в какие можно перенаправить.\n",
    "Для этого обратимся к графику выше.\n",
    "По проведённому исследованию предлагаю делать балансировку самокатов из ['куйбышева', 'дачная', 'пионерская', 'нагорная', 'пушкина']\n",
    "в ['мира', 'шевченко', 'заводская', 'матросова', 'вокзальная']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 Определим Топ-3 точки с самым высоким трафиком"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Определим точки с самым высоким трафиком.\n",
    "За трафик буду считать количество самокатов которое приезжает/уезжает из точки в час времени (кол-во/час).\n",
    "\n",
    "Считаю что в расчёт нужно брать все часы, так как ночью у некоторых точек может повышаться спрос.\n",
    "Если брать все часы, то среднее будет меньше чем если бы мы брали среднее лишь по дню, так как много часов простоя,\n",
    "но это справедливо для всех точек.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "location_demand_h = dict()\n",
    "df_location_mean_demand = pd.DataFrame({'location': [], \n",
    "                                        'mean_demand_h': [], \n",
    "                                        'mean_demand_d': [], \n",
    "                                        'median_demand_d': [], \n",
    "                                        'shapiro_pvalue': [],\n",
    "                                        'mean_cum_cost_h': [],\n",
    "                                        'cost_all_time': []})\n",
    "for location in locations:\n",
    "    df_location = locations_traffic[location].drop('traffic_cum', axis=1)\n",
    "    df_location.loc[:, 'traffic'] = df_location['traffic'].abs()\n",
    "    df_location_d = df_location.resample('1d', on='date').sum()\n",
    "    df_location = df_location.resample('1h', on='date').sum()\n",
    "    location_demand_h[location] = df_location\n",
    "    df_location_mean_demand.loc[len(df_location_mean_demand)] = [location, \n",
    "                                                                 df_location['traffic'].mean(), \n",
    "                                                                 df_location_d['traffic'].mean(),\n",
    "                                                                 df_location_d['traffic'].median(),\n",
    "                                                                 round(shapiro(df_location['traffic']).pvalue, 4),\n",
    "                                                                 df_location['cost'].mean(),\n",
    "                                                                 df_location['cost'].sum()\n",
    "                                                                 ]\n",
    "\n",
    "df_location_mean_demand = df_location_mean_demand.sort_values(by='mean_demand_h', key=lambda x: -x).reset_index().drop('index', axis=1)\n",
    "df_location_mean_demand.join(df_necessary_quantity_scoots.set_index('location'), on='location')\n",
    "df_location_mean_demand.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из таблицы видно что среднее ~ соответствует медиане, а также shapiro стремится к 0 (распред нормальное, можно судить по среднему)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Топ-3 точки с самым высоким трафиком\n",
    "\n",
    "df_location_mean_demand.loc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# луговая\n",
    "df_location_demand_h = location_demand_h['луговая']\n",
    "monthes = df_location_demand_h.index.month.unique()\n",
    "fig, axs = plt.subplots(nrows=len(monthes), figsize=(16, 16))\n",
    "for i, month in enumerate(monthes[:]):\n",
    "    df_location_demand_h_m = df_location_demand_h[df_location_demand_h.index.month == month]\n",
    "    x = df_location_demand_h_m.index\n",
    "    y = df_location_demand_h_m['traffic']\n",
    "\n",
    "    axs[i].plot_date(x, y, markersize=1)\n",
    "    axs[i].fill_between(x, y, 0, facecolor='blue', alpha=0.7)\n",
    "    axs[i].tick_params(axis='x', labelrotation=90)\n",
    "    axs[i].xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
    "\n",
    "    days = df_location_demand_h_m.resample('d').sum().index\n",
    "    xtickvals = [str(date.date().day) + \"-\" + name_num_day[get_num_of_day_on_week(date)] for date in days]\n",
    "\n",
    "    axs[i].set_xticks(days)\n",
    "    axs[i].set_xlim(days[0], days[len(days) - 1] + timedelta(days=1))\n",
    "    axs[i].set_ylim(0, 12)\n",
    "    axs[i].set_xticklabels(xtickvals, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'пушкина'\n",
    "'''\n",
    "дзержинского\t0.691384\n",
    "66\tсеверная\t0.691128\n",
    "67\tсосновая\t0.688484\n",
    "68\tовражная\t0.687967\n",
    "69\tзеленая\t0.687526\n",
    "70\tпролетарская\t0.686413\n",
    "71\tюжная\t0.686283\n",
    "72\tзаречная\t0.684932\n",
    "73\tсовхозная\t0.683513\n",
    "74\tкоммунальная\t0.683513\n",
    "75\tкооперативная\t0.682573\n",
    "76\tнагорная\t0.680780\n",
    "77\tмолодежная\t0.680066\n",
    "78\tдачная\t0.679519\n",
    "79\tгоголя\t0.679503\n",
    "80\tэнтузиастов\t0.676337\n",
    "81\tсоветская\t0.674814\n",
    "82\tсиреневая\t0.674399\n",
    "83\tжелезнодорожная\t0.672750\n",
    "84\tсолнечная\t0.670813\n",
    "85\tдружбы\t0.669983\n",
    "86\tкуйбышева\t0.667909\n",
    "87\tмира\t0.667634\n",
    "88\tстепная\t0.660315\n",
    "89\tнабережная\n",
    "'''\n",
    "df_location_demand_h = location_demand_h['гоголя']\n",
    "monthes = df_location_demand_h.index.month.unique()\n",
    "fig, axs = plt.subplots(nrows=4, figsize=(16, 10))\n",
    "for i, month in enumerate(range(4, 7 + 1)):\n",
    "    df_location_demand_h_m = df_location_demand_h[df_location_demand_h.index.month == month]\n",
    "    x = df_location_demand_h_m.index\n",
    "    y = df_location_demand_h_m['traffic']\n",
    "\n",
    "    axs[i].plot_date(x, y, markersize=1)\n",
    "    axs[i].fill_between(x, y, 0, facecolor='blue', alpha=0.7)\n",
    "    axs[i].tick_params(axis='x', labelrotation=90)\n",
    "    axs[i].xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
    "\n",
    "    days = df_location_demand_h_m.resample('d').sum().index\n",
    "    xtickvals = [str(date.date().day) + \"-\" + name_num_day[get_num_of_day_on_week(date)] for date in days]\n",
    "\n",
    "    axs[i].set_xticks(days)\n",
    "    axs[i].set_xlim(days[0], days[len(days) - 1] + timedelta(days=1))\n",
    "    axs[i].set_ylim(0, 12)\n",
    "    axs[i].set_xticklabels(xtickvals, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графиков точки с самым высоким средним спросом и самым низким можно увидить разницу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7 Самые популярные направления перемещения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_directions = pd.DataFrame()\n",
    "df_directions['direction_location'] = df_main['start_location'] + '->' + df_main['end_location']\n",
    "df_directions['direction_ditsrict'] = df_main['start_district'] + '->' + df_main['end_district']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_directions['direction_location'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_directions['direction_ditsrict'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "direction_location \n",
    "direction_district в топе находятся таки направления как "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Провека гипотез\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Проверка различия средней стоимости поездки по районам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Группировка данных по районам и вычисление средней стоимости поездки для каждого района\n",
    "mean_costs_by_district = df_main.groupby('start_district')['cost'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вывод средних значений стоимости поездок по районам\n",
    "print(\"Средняя стоимость поездок по районам:\")\n",
    "print(mean_costs_by_district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проведение однофакторного дисперсионного анализа (ANOVA)\n",
    "# Получение данных о стоимости поездок для каждого района\n",
    "costs_by_district = []\n",
    "for district in df_main['start_district'].unique():\n",
    "    costs_by_district.append(df_main[df_main['start_district'] == district]['cost'])\n",
    "\n",
    "# Проведение ANOVA\n",
    "f_statistic, p_value = f_oneway(*costs_by_district)\n",
    "\n",
    "# Вывод результатов ANOVA\n",
    "print(\"\\nРезультаты однофакторного дисперсионного анализа (ANOVA):\")\n",
    "print(\"F-статистика:\", f_statistic)\n",
    "print(\"p-значение:\", p_value)\n",
    "\n",
    "# Оценка статистической значимости\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"\\nОтвергаем нулевую гипотезу: средние значения стоимости поездок по районам различаются.\")\n",
    "else:\n",
    "    print(\"\\nНе отвергаем нулевую гипотезу: нет статистически значимых различий в средней стоимости поездок по районам.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод: Средняя стоимость поездки не отличается по районам**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Проверка зависимости дня недели от спроса на самокты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавление столбца для дня недели (0 - 4 будни, 5 - 6  выходные)\n",
    "df_main['day_of_week'] = df_main['start_date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Агрегирование данных\n",
    "daily_demand = df_main.groupby('day_of_week').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация результатов\n",
    "plt.figure(figsize=(10, 6))\n",
    "daily_demand.plot(kind='bar', color='skyblue')\n",
    "plt.title('Спрос на самокаты по дням недели')\n",
    "plt.xlabel('День недели')\n",
    "plt.ylabel('Количество поездок')\n",
    "plt.xticks(range(7), ['Пн', 'Вт', 'Ср', 'Чт', 'Пт', 'Сб', 'Вс'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод: Из графика видно, что на спрос влияет день недели. Следоватьельно гипотеза подтвердилась**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Проверка длительности поездок по выходным и будням"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на будни и выходные\n",
    "weekday_trips = df_main[df_main['day_of_week'] < 5]\n",
    "weekend_trips = df_main[df_main['day_of_week'] >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисление длительности поездок в минутах\n",
    "weekday_trips['duration'] = (weekday_trips['end_date'] - weekday_trips['start_date']).dt.total_seconds() / 60\n",
    "weekend_trips['duration'] = (weekend_trips['end_date'] - weekend_trips['start_date']).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вывод средних длительностей поездок\n",
    "print(\"Средняя длительность поездок по будням:\", weekday_trips['duration'].mean(), \"минут\")\n",
    "print(\"Средняя длительность поездок по выходным:\", weekend_trips['duration'].mean(), \"минут\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод: В среднем поездки по времени одинакоыве, следоватьельно гипотеза опровегнута**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Регрессионное моделирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_scoot.head(3)\n",
    "dem_scoot_index_date = dem_scoot.set_index('start_date')\n",
    "train, test = train_test_split(dem_scoot_index_date['frequency'], test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(train, \n",
    "                order = (3, 1, 1), \n",
    "                seasonal_order = (2, 1, 1, 24))\n",
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = test.index[0]\n",
    " \n",
    "# и закончится в конце тестового\n",
    "end = test.index[-1]\n",
    "  \n",
    "# применим метод predict\n",
    "predictions = result.predict(start, end)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthes = dem_scoot['start_date'].dt.month.unique()\n",
    "fig, axs = plt.subplots(nrows=len(monthes), figsize=(16, 16))\n",
    "\n",
    "for i, month in enumerate(monthes):\n",
    "    # выведем три кривые (обучающая, тестовая выборка и тестовый прогноз)\n",
    "    monthes_train = train.index.month.unique()\n",
    "    monthes_test = test.index.month.unique()\n",
    "    monthes_predictions = predictions.index.month.unique()\n",
    "    if month in monthes_train:\n",
    "        data = train[train.index.month == month]\n",
    "        x = data.index\n",
    "        y = data.values\n",
    "        axs[i].plot(x, y, color='black')\n",
    "    if month in monthes_test:\n",
    "        data = test[test.index.month == month]\n",
    "        x = data.index\n",
    "        y = data.values\n",
    "        axs[i].plot(x, y, color='green')\n",
    "    if month in monthes_predictions:\n",
    "        data = predictions[predictions.index.month == month]\n",
    "        x = data.index\n",
    "        y = data.values\n",
    "        axs[i].plot(x, y, color='red')\n",
    "    \n",
    "    # days = x.reset_index().set_index('date').resample('d').sum().reset_index().drop('index', axis=1)['date']\n",
    "    # xtickvals = [str(date.date().day) + \"-\" + name_num_day[get_num_of_day_on_week(date)] for date in days]\n",
    "    \n",
    "\n",
    "    # axs[i].grid(alpha=0.2)\n",
    "    # axs[i].xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
    "    # axs[i].set_xticks(days)\n",
    "    # axs[i].set_xlim(days.iloc[0], days.iloc[len(days) - 1] + timedelta(days=1))\n",
    "    # axs[i].set_ylim(-20, 20)\n",
    "\n",
    "    # axs[i].set_xticklabels(xtickvals, rotation=90)\n",
    "    \n",
    "    # axs[i].set_xlabel('Время')\n",
    "    # axs[i].set_ylabel('Трафик')\n",
    "    # axs[i].set_title(f'Спрос в {}')\n",
    "\n",
    "\n",
    " \n",
    "# рассчитаем MSE\n",
    "print(mean_squared_error(test, predictions))\n",
    " \n",
    "# и RMSE\n",
    "print(np.sqrt(mean_squared_error(test, predictions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
